# ì¤‘ë³µ Batch Job ìƒì„± ë¬¸ì œ í•´ê²°

## ë¬¸ì œ ì •ì˜

### ì¦ìƒ

- Frontendì—ì„œ ë¹„ë””ì˜¤ë¥¼ 1ë²ˆ ì—…ë¡œë“œí•˜ë©´ **AWS Batchì— 2ê°œì˜ Jobì´ ìƒì„±**ë˜ëŠ” í˜„ìƒ ë°œìƒ
- ë™ì¼í•œ ë¹„ë””ì˜¤ì— ëŒ€í•´ ì¤‘ë³µëœ ë¶„ì„ ì‘ì—…ì´ ì‹¤í–‰ë˜ì–´ ë¦¬ì†ŒìŠ¤ ë‚­ë¹„ ë° ë¹„ìš© ì¦ê°€

### ë°œìƒ ì‹œì 

- 2025ë…„ 12ì›” 29ì¼
- Frontend â†’ S3 Pre-signed URL ì—…ë¡œë“œ â†’ SQS â†’ Lambda â†’ Batch íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì¤‘ ë°œê²¬

### ì˜í–¥

- GPU ì¸ìŠ¤í„´ìŠ¤(g5.xlarge) ì¤‘ë³µ ì‹¤í–‰ìœ¼ë¡œ ë¹„ìš© 2ë°° ì¦ê°€
- DBì— ì¤‘ë³µ Event ë°ì´í„° ì €ì¥
- SQS ë©”ì‹œì§€ ì¤‘ë³µ ì²˜ë¦¬

## ì›ì¸ ë¶„ì„

### 1ì°¨ ì›ì¸: SQS ì¤‘ë³µ ë©”ì‹œì§€

**S3 Event Notificationì´ ë™ì¼í•œ ì—…ë¡œë“œì— ëŒ€í•´ 2ê°œì˜ SQS ë©”ì‹œì§€ë¥¼ ì „ì†¡**

#### ì¦ê±° ë¡œê·¸ (Lambda CloudWatch):

```
RequestId: fd9e8910-84dc-5b89-86f6-e8dccc1b5867
- video_id: 84 (from message body) âœ…
- Job created: 972123fb-b18d-42a3-a4d4-4e58ac7874ae

RequestId: 94eb0697-6cce-51c3-9384-675b24759a91
- video_id: 2025 (from S3 path parsing) âŒ
- Duplicate detected and skipped
```

### 2ì°¨ ì›ì¸: Lambda Job ì´ë¦„ ìƒì„± ë°©ì‹

**ê¸°ì¡´ ì½”ë“œ:**

```python
timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')
video_filename = key.split('/')[-1].split('.')[0]
job_name = f"video-process-{timestamp}-{video_filename[:20]}"
```

**ë¬¸ì œì :**

- Timestamp í¬í•¨ìœ¼ë¡œ **ë§¤ë²ˆ ë‹¤ë¥¸ Job ì´ë¦„ ìƒì„±**
- ê°™ì€ ë¹„ë””ì˜¤ë¼ë„ ë‹¤ë¥¸ Jobìœ¼ë¡œ ì¸ì‹ë˜ì–´ ì¤‘ë³µ ì²´í¬ ë¶ˆê°€ëŠ¥
- Job ì´ë¦„ë§Œìœ¼ë¡œëŠ” ì¤‘ë³µ íŒë³„ ë¶ˆê°€

### 3ì°¨ ì›ì¸: S3 Path êµ¬ì¡° ë¶ˆì¼ì¹˜

**Backend ì—…ë¡œë“œ ê²½ë¡œ:**

```
videos/2025/12/29/f762f997-48bb-4ef7-9412-7ede74c1a993_20250526_193726.mp4
```

**Lambdaê°€ ê¸°ëŒ€í•œ ê²½ë¡œ:**

```
videos/{video_id}/{filename}
```

**ê²°ê³¼:**

- Lambdaê°€ ë‚ ì§œ "2025"ë¥¼ video_idë¡œ ì˜ëª» ì¶”ì¶œ
- ì²« ë²ˆì§¸ ë©”ì‹œì§€: video_id=84 (message bodyì—ì„œ ì¶”ì¶œ) âœ…
- ë‘ ë²ˆì§¸ ë©”ì‹œì§€: video_id=2025 (S3 pathì—ì„œ ì˜ëª» ì¶”ì¶œ) âŒ

## í•´ê²° ë°©ë²•

### 1ë‹¨ê³„: Lambda ì¤‘ë³µ ë°©ì§€ ë¡œì§ ê°•í™”

#### í•´ê²° ì „ëµ

1. **Deterministic Job Name**: video_id ê¸°ë°˜ìœ¼ë¡œ í•­ìƒ ë™ì¼í•œ Job ì´ë¦„ ìƒì„±
2. **2ë‹¨ê³„ ì¤‘ë³µ ì²´í¬**:
   - 1ì°¨: Job Nameìœ¼ë¡œ ë¹ ë¥¸ ì²´í¬ (API í˜¸ì¶œ ë¶ˆí•„ìš”)
   - 2ì°¨: S3 Keyë¡œ ì¶”ê°€ í™•ì¸ (5ë¶„ ì´ë‚´ Job)

#### ìˆ˜ì •ëœ ì½”ë“œ

**íŒŒì¼**: `lambda/sqs_to_batch.py`

```python
# âœ… Deterministic Job Name ìƒì„±
job_name = f"video-process-{video_id}"
logger.info(f"ğŸš€ Submitting job: {job_name}")

# ğŸ”„ ê°•í™”ëœ ì¤‘ë³µ Job ë°©ì§€
duplicate_found = False
try:
    active_statuses = ['SUBMITTED', 'PENDING', 'RUNNABLE', 'STARTING', 'RUNNING']
    all_active_jobs = []

    for status in active_statuses:
        response = batch_client.list_jobs(
            jobQueue=JOB_QUEUE,
            jobStatus=status,
            maxResults=100
        )
        all_active_jobs.extend(response.get('jobSummaryList', []))

    logger.info(f"ğŸ“Š Total active jobs: {len(all_active_jobs)}")

    # ğŸ¯ 1ì°¨: job nameìœ¼ë¡œ ë¹ ë¥¸ ì²´í¬
    for job_summary in all_active_jobs:
        if job_summary.get('jobName') == job_name:
            logger.warning(
                f"âš ï¸ DUPLICATE JOB DETECTED by job name! "
                f"video_id: {video_id}, "
                f"job_name: {job_name}, "
                f"Existing Job ID: {job_summary['jobId']}"
            )
            duplicate_found = True
            successful_count += 1  # ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬ (SQS ë©”ì‹œì§€ ì‚­ì œ)
            break

    # ğŸ¯ 2ì°¨: S3 keyë¡œ ì¶”ê°€ í™•ì¸ (job nameì´ ë‹¤ë¥¼ ê²½ìš° ëŒ€ë¹„)
    if not duplicate_found:
        current_time = int(datetime.now().timestamp() * 1000)
        for job_summary in all_active_jobs:
            job_id = job_summary['jobId']
            created_at = job_summary.get('createdAt', 0)
            time_diff_seconds = (current_time - created_at) / 1000

            # 5ë¶„ ì´ë‚´ì— ìƒì„±ëœ Jobë§Œ í™•ì¸
            if time_diff_seconds < 300:
                try:
                    job_detail = batch_client.describe_jobs(jobs=[job_id])
                    if job_detail.get('jobs'):
                        job_tags = job_detail['jobs'][0].get('tags', {})
                        existing_key = job_tags.get('VideoKey', '')

                        if existing_key == key:
                            logger.warning(
                                f"âš ï¸ DUPLICATE JOB DETECTED by S3 key! "
                                f"S3 Key: {key}, "
                                f"Existing Job ID: {job_id}"
                            )
                            duplicate_found = True
                            successful_count += 1
                            break
                except Exception as detail_error:
                    logger.debug(f"Error checking job details: {detail_error}")

    if duplicate_found:
        logger.info("âœ‹ Skipping job submission due to duplicate detection.")
        continue  # ë‹¤ìŒ ë©”ì‹œì§€ë¡œ

except Exception as check_error:
    logger.warning(f"âš ï¸ Failed to check for duplicate jobs: {check_error}")
```

### 2ë‹¨ê³„: video_id ì¶”ì¶œ ë¡œì§ ê°œì„ 

**ìš°ì„ ìˆœìœ„ ì •ì˜:**

1. SQS ë©”ì‹œì§€ bodyì˜ `video.id` í•„ë“œ (ìµœìš°ì„ )
2. MessageAttributesì˜ `video_id`
3. S3 key ê²½ë¡œì—ì„œ ì¶”ì¶œ (ë‹¨, ìˆ«ìì¸ì§€ ê²€ì¦)
4. Fallback: íŒŒì¼ëª…ì—ì„œ ìˆ«ì ì¶”ì¶œ

**ë³€ê²½ì‚¬í•­:**

```python
# 3. S3 key ê²½ë¡œì—ì„œ ì¶”ì¶œ: videos/{video_id}/{filename}
if not video_id:
    try:
        key_parts = key.split('/')
        if len(key_parts) >= 2 and key_parts[0] == 'videos':
            extracted_id = key_parts[1]
            # âœ… ìˆ«ìì¸ì§€ í™•ì¸ ì¶”ê°€
            if extracted_id.isdigit():
                video_id = extracted_id
                logger.info(f"Extracted video_id from S3 key path: {video_id}")
            else:
                logger.warning(f"S3 key path segment is not a number: {extracted_id}")
    except Exception as e:
        logger.debug(f"Could not extract video_id from S3 key path: {e}")
```

### 3ë‹¨ê³„: Frontend ì—ëŸ¬ ìˆ˜ì •

**ë¬¸ì œ**: Event ë°ì´í„°ì˜ `gender_score`ê°€ `null`ì¼ ë•Œ `.toFixed()` í˜¸ì¶œ ì‹œ ì—ëŸ¬ ë°œìƒ

**íŒŒì¼**: `front/components/event-timeline.tsx`

```tsx
// âŒ Before
<span>{event.gender} ({event.age}ì„¸, {event.gender_score.toFixed(1)}% ì‹ ë¢°ë„)</span>

// âœ… After
<span>{event.gender} ({event.age}ì„¸, {event.gender_score ? event.gender_score.toFixed(1) : '0'}% ì‹ ë¢°ë„)</span>
```

## ê²€ì¦ ë° í…ŒìŠ¤íŠ¸

### í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

1. Frontendì—ì„œ ë¹„ë””ì˜¤ ì—…ë¡œë“œ
2. Lambda ë¡œê·¸ í™•ì¸
3. Batch Job ê°œìˆ˜ í™•ì¸

### í…ŒìŠ¤íŠ¸ ê²°ê³¼ (2025-12-29)

#### Lambda ë¡œê·¸:

```
[INFO] Received 1 messages from SQS
[INFO] Processing video: s3://capstone-dev-raw/videos/2025/12/29/f762f997-...
[INFO] Extracted video_id from message body: 84
[INFO] âœ… Final video_id: 84
[INFO] ğŸš€ Submitting job: video-process-84
[INFO] ğŸ“Š Total active jobs: 0
[INFO] âœ… Successfully submitted job: 972123fb-b18d-42a3-a4d4-4e58ac7874ae

# ë‘ ë²ˆì§¸ SQS ë©”ì‹œì§€ ì²˜ë¦¬
[INFO] Received 1 messages from SQS
[INFO] ğŸ“Š Total active jobs: 1
[WARNING] âš ï¸ DUPLICATE JOB DETECTED by job name!
          video_id: 84, job_name: video-process-84
          Existing Job ID: 972123fb-b18d-42a3-a4d4-4e58ac7874ae (status: SUBMITTED)
[INFO] âœ‹ Skipping job submission due to duplicate detection.
[INFO] Processing complete: 1 succeeded, 0 failed
```

#### Batch Jobs:

```bash
$ aws batch list-jobs --job-queue capstone-dev-memi-gpu-queue --job-status RUNNABLE

JobId: 972123fb-b18d-42a3-a4d4-4e58ac7874ae
JobName: video-process-84
Status: RUNNABLE
```

**ê²°ê³¼**: âœ… **1ê°œì˜ Jobë§Œ ìƒì„±ë¨** (ì¤‘ë³µ ë°©ì§€ ì„±ê³µ)

## ë°°í¬

### Lambda ë°°í¬

```powershell
cd E:\capstone\lambda
Compress-Archive -Path sqs_to_batch.py -DestinationPath deployment-package.zip
aws lambda update-function-code `
  --function-name capstone-dev-sqs-to-batch `
  --zip-file fileb://deployment-package.zip `
  --region ap-northeast-2
```

### ë°°í¬ í™•ì¸

```json
{
  "FunctionName": "capstone-dev-sqs-to-batch",
  "LastModified": "2025-12-31T12:20:25.000+0000",
  "CodeSize": 4300,
  "CodeSha256": "w17gVOGVWKQGTy4cNhh98W2VyPajEVVt4cLDNipq4vk=",
  "LastUpdateStatus": "Successful"
}
```

## ì¶”ê°€ ê°œì„  ì‚¬í•­

### SQS ì¤‘ë³µ ë©”ì‹œì§€ ê·¼ë³¸ ì›ì¸ ì¡°ì‚¬ í•„ìš”

- S3 Event Notification ì„¤ì • ì¬ê²€í† 
- Content-Based Deduplication í™œì„±í™” ê³ ë ¤
- SQS FIFO íë¡œ ì „í™˜ ê²€í† 

### ëª¨ë‹ˆí„°ë§ ê°•í™”

- CloudWatch Alarm: ì¤‘ë³µ Job ê°ì§€ ì‹œ ì•Œë¦¼
- Lambda ë¡œê·¸ ë©”íŠ¸ë¦­: "DUPLICATE JOB DETECTED" ì¹´ìš´íŠ¸

## ê´€ë ¨ íŒŒì¼

- `lambda/sqs_to_batch.py` - Lambda í•¨ìˆ˜ (ì¤‘ë³µ ë°©ì§€ ë¡œì§)
- `front/components/event-timeline.tsx` - Frontend ì—ëŸ¬ ìˆ˜ì •
- `terraform/batch-memi-gpu.tf` - Batch Job Definition
- `terraform/sqs.tf` - SQS í ì„¤ì •

## ì°¸ê³  ìë£Œ

- [AWS Batch Best Practices - Job Idempotency](https://docs.aws.amazon.com/batch/latest/userguide/best-practices.html)
- [SQS Message Deduplication](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/using-messagededuplicationid-property.html)
- [S3 Event Notification Troubleshooting](https://docs.aws.amazon.com/AmazonS3/latest/userguide/notification-troubleshooting.html)

---

**ì‘ì„±ì¼**: 2025-12-31  
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-12-31
